name: Run Analytics Aggregation V2

on:
  workflow_dispatch:
    inputs:
      pipeline_id:
        description: 'Pipeline run ID (optional)'
        required: false
        type: string
        default: 'manual-run'
      sensor_data_status:
        description: 'Status of sensor data collection'
        required: false
        type: string
        default: 'manual'
      regional_data_status:
        description: 'Status of regional data collection'
        required: false
        type: string
        default: 'manual'
  workflow_call:
    inputs:
      pipeline_id:
        description: 'Pipeline run ID'
        required: false
        type: string
      sensor_data_status:
        description: 'Status of sensor data collection'
        required: false
        type: string
      regional_data_status:
        description: 'Status of regional data collection'
        required: false
        type: string

env:
  NODE_VERSION: '20'

jobs:
  aggregate:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm install @supabase/supabase-js node-fetch@2

      - name: Run analytics aggregation
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          PIPELINE_ID: ${{ inputs.pipeline_id }}
          HOURS_TO_AGGREGATE: "24"
          FORCE_REAGGREGATE: "false"
        run: |
          echo "üîÑ Running analytics aggregation..."
          echo "Pipeline ID: ${{ inputs.pipeline_id }}"
          echo "Sensor data status: ${{ inputs.sensor_data_status }}"
          echo "Regional data status: ${{ inputs.regional_data_status }}"
          echo "Hours to aggregate: $HOURS_TO_AGGREGATE"
          
          # Run the aggregation script
          cd scripts
          if [ -f "run_hourly_aggregation.js" ]; then
            echo "Running standard aggregation (last 3 hours)..."
            node run_hourly_aggregation.js
            
            # Also run extended aggregation for missing data
            if [ -f "run_hourly_aggregation_extended.js" ]; then
              echo ""
              echo "Running extended aggregation (last 24 hours)..."
              node run_hourly_aggregation_extended.js
            fi
          else
            echo "‚ö†Ô∏è Aggregation script not found, skipping..."
          fi

      - name: Generate summary
        if: always()
        run: |
          cat << EOF > $GITHUB_STEP_SUMMARY
          ## Analytics Aggregation Summary
          
          **Pipeline**: ${{ inputs.pipeline_id }}
          **Status**: ${{ job.status }}
          
          ### Input Status
          - Sensor Data: ${{ inputs.sensor_data_status }}
          - Regional Data: ${{ inputs.regional_data_status }}
          
          ### Results
          Check logs for detailed aggregation results.
          EOF